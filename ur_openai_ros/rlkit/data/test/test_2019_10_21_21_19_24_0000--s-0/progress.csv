trainer/Policy Loss,evaluation/env_infos/initial/total_distance Mean,exploration/Returns Mean,trainer/Policy Action Mean,exploration/Actions Min,exploration/Returns Std,trainer/Q1 Predictions Max,evaluation/env_infos/initial/total_distance Std,replay_buffer/size,exploration/env_infos/final/total_distance Mean,evaluation/path length Std,trainer/Bellman Errors 1 Std,exploration/Returns Max,evaluation/env_infos/final/total_distance Max,trainer/Q2 Predictions Min,time/data storing (s),exploration/env_infos/total_distance Std,evaluation/env_infos/initial/total_distance Min,evaluation/path length Mean,exploration/Actions Mean,trainer/Q Targets Min,exploration/num steps total,trainer/Bellman Errors 1 Max,exploration/Rewards Min,evaluation/Actions Mean,evaluation/Returns Max,exploration/env_infos/total_distance Min,trainer/Policy Action Max,evaluation/env_infos/total_distance Min,evaluation/env_infos/total_distance Std,evaluation/path length Min,evaluation/env_infos/final/total_distance Std,trainer/Q2 Predictions Mean,evaluation/Rewards Max,trainer/Q Targets Mean,trainer/Bellman Errors 2 Min,evaluation/num paths total,evaluation/Returns Std,trainer/QF2 Loss,exploration/env_infos/total_distance Max,evaluation/env_infos/final/total_distance Mean,trainer/Bellman Errors 2 Mean,trainer/Bellman Errors 1 Min,trainer/Q Targets Std,evaluation/num steps total,exploration/Rewards Max,trainer/Q1 Predictions Mean,trainer/Bellman Errors 1 Mean,trainer/Q1 Predictions Min,exploration/env_infos/initial/total_distance Min,evaluation/Returns Mean,evaluation/Average Returns,exploration/path length Min,Epoch,time/saving (s),exploration/Returns Min,evaluation/env_infos/initial/total_distance Max,time/epoch (s),exploration/path length Std,evaluation/Rewards Min,trainer/Q2 Predictions Max,time/evaluation sampling (s),evaluation/Actions Min,exploration/env_infos/initial/total_distance Max,exploration/Rewards Mean,exploration/env_infos/final/total_distance Max,trainer/Policy Action Std,time/logging (s),evaluation/path length Max,trainer/Q Targets Max,exploration/path length Mean,exploration/num paths total,trainer/Bellman Errors 2 Std,evaluation/env_infos/final/total_distance Min,exploration/env_infos/initial/total_distance Mean,evaluation/Num Paths,evaluation/Rewards Std,trainer/Bellman Errors 2 Max,time/exploration sampling (s),evaluation/Actions Std,exploration/env_infos/final/total_distance Std,evaluation/env_infos/total_distance Max,exploration/env_infos/total_distance Mean,exploration/path length Max,time/total (s),evaluation/Returns Min,exploration/env_infos/initial/total_distance Std,exploration/Num Paths,exploration/Average Returns,exploration/env_infos/final/total_distance Min,trainer/QF1 Loss,evaluation/env_infos/total_distance Mean,evaluation/Rewards Mean,trainer/Q1 Predictions Std,exploration/Actions Max,exploration/Actions Std,exploration/Rewards Std,time/training (s),evaluation/Actions Max,trainer/Policy Action Min,trainer/Q2 Predictions Std
0.04303237,0.8739729984906797,-88.83092654221797,0.00069742225,-0.28434002285779736,0.0,0.008585006,0.0,200,0.8942768537801493,0.0,0.06774796,-88.83092654221797,0.7266014923534104,-0.0013259664,0.005149425996933132,0.022870506160427722,0.8739729984906797,500.0,-0.0022503278914416543,-0.9689342,200,0.95504236,-0.9623669217245447,0.00067998806,-321.1510794753976,0.8937455341257813,0.0047129258,0.7266014923534104,0.042698350661653624,500,0.0,-0.0010352405,-0.5279497286902032,-0.8945292,0.64685506,1,0.0,0.79975665,0.9810030182035857,0.7266014923534104,0.7997566,0.66240466,0.03771732,500,-0.7987810797697781,0.008397646,0.81669736,0.00816326,0.9711484277068291,-321.1510794753976,-321.1510794753976,100,0,0.01544338499661535,-88.83092654221797,0.8739729984906797,23.451795944027253,0.0,-0.7638288020907895,-0.0007139833,12.348814020006103,-0.0043744682,0.9711484277068291,-0.8883092654221795,0.8942768537801493,0.002923548,0.0033990570082096383,500,-0.80543125,100.0,2,0.067148626,0.7266014923534104,0.9711484277068291,1,0.06835324834583942,0.936763,3.72305964800762,0.002833637,0.0,0.8739729984906797,0.9422240738646757,100,27.756109269030276,-321.1510794753976,0.0,1,-88.83092654221797,0.8942768537801493,0.8166975,0.8002993251287728,-0.6423021589507947,8.436399e-05,0.40303186017388004,0.10593746478493357,0.042878257841563024,7.355930408011773,0.0044315946,-0.0044293054,0.00011646265
3.1427882,0.8739713156481701,-53.74303740383291,0.33163288,-1.0,0.0,-0.9479308,0.0,300,0.21454211593484393,0.0,36.979378,-53.74303740383291,0.5650666264635074,-10.144799,0.0009236339974449947,0.3454559721032618,0.8739713156481701,500.0,0.32198593831450745,-2.08315,300,86.462746,-1.4068821402899188,0.3045578,-158.46056054430656,0.20370366578091334,1.0,0.2352982280112712,0.10946139834267435,500,0.0,-4.34099,-0.055365256105244176,-1.0652934,3.1995743e-08,2,0.0,28.75594,1.1861206263655981,0.5650666264635074,28.755938,2.3297845e-07,0.31397122,1000,-0.041495183452582046,-4.30596,28.139729,-10.030097,1.0526816893307458,-158.46056054430656,-158.46056054430656,100,1,0.021503093012142926,-53.74303740383291,0.8739713156481701,27.413784489021054,0.0,-0.7638258605757934,-0.9473233,13.249838385003386,-1.0,1.0526816893307458,-0.537430374038329,0.21454211593484393,0.9414853,0.007506271009333432,500,-0.72982496,100.0,3,37.798904,0.5650666264635074,1.0526816893307458,1,0.11716570162751186,88.6041,5.3997164930042345,0.8807465,0.0,0.8739713156481701,0.646599215415948,100,55.17434135703661,-158.46056054430656,0.0,1,-53.74303740383291,0.21454211593484393,28.139732,0.5522131140795908,-0.31692112108861276,4.3211308,1.0,0.9064247280337614,0.48504435953125785,8.734296612994513,1.0,-1.0,4.366754
1.1602815,1.1132549410847046,-37.07346413080721,0.33333033,-1.0,0.0,-0.6711778,0.0,400,0.534784518878677,0.0,1.541967,-37.07346413080721,0.5684066892027735,-3.1761892,0.0013005200016777962,0.2847628855771171,1.1132549410847046,500.0,0.31913337577383183,-2.5547533,400,4.1362267,-1.416388587178628,0.33333334,-164.6476140309026,0.2039436617393562,1.0,0.23526771998023252,0.1260506166032668,500,0.0,-1.5331061,-0.0553509000646971,-1.116261,4.5762224e-08,3,0.0,0.7830086,1.1901212489400514,0.5684066892027735,0.7830087,4.1900563e-09,0.377918,1500,-0.041593017163656945,-1.604423,0.96760976,-3.5365167,1.1014902814963314,-164.6476140309026,-164.6476140309026,100,2,0.011166423006216064,-37.07346413080721,1.1132549410847046,31.61691381499986,0.0,-1.2659677599054702,-0.7383259,14.912451566997333,-1.0,1.1014902814963314,-0.37073464130807227,0.534784518878677,0.942804,0.004093366995221004,500,-0.37711045,100.0,4,1.2260994,0.5684066892027735,1.1014902814963314,1,0.16580444032638486,3.3758266,8.263644102000399,0.942809,0.0,1.125152327423034,0.5381865292868875,100,86.79867981703137,-164.6476140309026,0.0,1,-37.07346413080721,0.534784518878677,0.9676098,0.5598271787933675,-0.3292952280618048,1.0412215,1.0,0.9059529773822583,0.3949383991916559,8.424257835999015,1.0,-1.0,0.94803876
