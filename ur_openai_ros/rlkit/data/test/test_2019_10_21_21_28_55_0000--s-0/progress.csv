trainer/Bellman Errors 1 Max,time/epoch (s),trainer/Q Targets Mean,trainer/Bellman Errors 2 Min,evaluation/env_infos/total_distance Std,evaluation/env_infos/total_distance Min,exploration/env_infos/total_distance Std,exploration/env_infos/final/total_distance Mean,trainer/Policy Action Max,trainer/Bellman Errors 1 Std,evaluation/path length Std,time/total (s),trainer/Q2 Predictions Min,trainer/Policy Action Mean,trainer/Bellman Errors 1 Mean,exploration/Actions Mean,evaluation/Num Paths,evaluation/env_infos/initial/total_distance Min,exploration/env_infos/initial/total_distance Std,exploration/env_infos/initial/total_distance Min,trainer/Q Targets Max,evaluation/Rewards Min,exploration/Returns Min,evaluation/env_infos/final/total_distance Std,evaluation/env_infos/initial/total_distance Mean,trainer/Policy Action Std,exploration/path length Std,evaluation/Returns Max,evaluation/Actions Std,evaluation/path length Max,trainer/Bellman Errors 1 Min,time/data storing (s),evaluation/num paths total,exploration/env_infos/final/total_distance Min,evaluation/Returns Mean,trainer/Policy Loss,time/saving (s),evaluation/Rewards Max,evaluation/env_infos/final/total_distance Min,evaluation/env_infos/initial/total_distance Std,evaluation/Returns Std,exploration/Num Paths,exploration/env_infos/total_distance Min,exploration/Actions Min,exploration/Returns Std,exploration/path length Min,trainer/Bellman Errors 2 Mean,trainer/Q Targets Min,time/logging (s),exploration/num steps total,trainer/Q2 Predictions Std,evaluation/Rewards Std,exploration/Rewards Max,exploration/env_infos/total_distance Max,exploration/env_infos/initial/total_distance Mean,exploration/num paths total,evaluation/env_infos/final/total_distance Max,evaluation/num steps total,exploration/env_infos/total_distance Mean,trainer/Q2 Predictions Max,trainer/Bellman Errors 2 Std,evaluation/path length Mean,Epoch,exploration/Actions Std,trainer/Bellman Errors 2 Max,evaluation/path length Min,trainer/Q1 Predictions Std,time/evaluation sampling (s),evaluation/Actions Max,exploration/path length Mean,evaluation/env_infos/final/total_distance Mean,exploration/Rewards Std,trainer/Q1 Predictions Min,exploration/Actions Max,exploration/path length Max,trainer/QF1 Loss,evaluation/env_infos/initial/total_distance Max,time/exploration sampling (s),exploration/Returns Max,trainer/Q1 Predictions Max,evaluation/Returns Min,exploration/Rewards Mean,evaluation/Actions Mean,replay_buffer/size,exploration/env_infos/initial/total_distance Max,exploration/Returns Mean,exploration/env_infos/final/total_distance Std,trainer/Q1 Predictions Mean,exploration/Rewards Min,evaluation/Rewards Mean,evaluation/Actions Min,evaluation/env_infos/total_distance Max,trainer/QF2 Loss,evaluation/env_infos/total_distance Mean,exploration/Average Returns,trainer/Policy Action Min,time/training (s),trainer/Q Targets Std,exploration/env_infos/final/total_distance Max,evaluation/Average Returns,trainer/Q2 Predictions Mean
0.8142828,29.93517239598441,-0.8337065,0.51352566,0.029089518346331642,0.8820460812548777,0.013032557391980207,0.923506463035594,0.002262246,0.078738905,0.0,35.780139772963594,0.0005902607,-0.001270448,0.6934704,-0.0014677713434801455,1,0.8820460812548777,0.0,0.9262632279014608,-0.7154936,-0.9654384838912522,-86.75069362852967,0.0,0.8820460812548777,0.0023614555,0.0,-435.2895155589437,0.0023582396,500,0.50843656,0.0006684360123472288,1,0.923506463035594,-435.2895155589437,0.053933796,0.015868852991843596,-0.7780052894570864,0.9825672922966916,0.0,0.0,1,0.9089666163298233,-0.2940792457002883,0.0,100,0.69903076,-0.9047726,0.0033596189896343276,200,0.00011170854,0.05424963951186462,-0.8262203096020883,0.952206924891459,0.9262632279014608,2,0.9825672922966916,500,0.9313093410532944,0.0012089706,0.07905812,500.0,0,0.10460399413116499,0.820437,500,0.00010541011,20.128514222000376,0.0022179757,100.0,0.9825672922966916,0.024246098001491585,-0.0026051495,0.3476544387703482,100,0.69347036,0.8820460812548777,2.4768855729926145,-86.75069362852967,-0.002023998,-435.2895155589437,-0.8675069362852967,-0.0012764791,200,0.9262632279014608,-86.75069362852967,0.0,-0.002365836,-0.9066980278112486,-0.8705790311178871,-0.0053871246,0.9825672922966916,0.69903076,0.9325946767166674,-86.75069362852967,-0.005350305,7.309875692997593,0.04841079,0.923506463035594,-435.2895155589437,0.0009714613
